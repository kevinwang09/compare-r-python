---
title: "Compare R and Python: basic classifiers"
output: 
  html_document:
    css: style.css
    toc: true
    toc_depth: 1
---

For this comparison, I will compare the `scikit-learn` library in `Python` and the newly developed `tidymodels` meta-package in `R`. The main reason that I have chosen these two is because they share a lot of similarities and imposed strict frameworks in data pre-processing, modelling and evaluations.

The data that I will use is the `penguins` data from the `R` package `palmerpenguins`, which you can learn more about [here](https://allisonhorst.github.io/palmerpenguins/articles/intro.html). The response variable is a `factor` variable, `species`, indicating the species of a penguin. The other predictor variables are a mix of both numeric and factor variables. For convenience, I have reduced the number of species to two and extracted the data below in a CSV format so that Python can also use this data through `pd.read_csv`.

```{r, eval = FALSE}
library(palmerpenguins)
library(tidyverse)

penguins %>% 
  na.omit %>% 
  dplyr::filter(species %in% c("Adelie", "Chinstrap")) %>% 
  readr::write_csv(path = "data/penguins_complete.csv")
```

# Importing data and getting a summary

::: {.left}
## `R`: `tidyverse`

```{r, message = FALSE}
library(tidyverse)
penguins = readr::read_csv(file = "data/penguins_complete.csv")
penguins %>% colnames()
```
:::

::: {.right}
## `Python`: `pandas`

```{python}
import pandas as pd
penguins = pd.read_csv("data/penguins_complete.csv")
penguins.columns
```
:::

::: {style="margin-bottom:1000px;"}
:::

# Decision tree classification

::: {.left}
## `R`

```{r, message = FALSE}
##
##
##
##
##
##
##
##
library(rpart)
library(rpart.plot)

feature_set = c('bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g')
sub_penguins = penguins[,c('species', feature_set)]
dtc_model = rpart::rpart(species ~ ., data = sub_penguins,
                         control = rpart.control(maxdepth = 1))
table(sub_penguins$species, 
      predict(dtc_model, type = "class"))

rpart.plot(dtc_model)
```
:::

::: {.right}
## `Python`

```{python}
from sklearn.tree import DecisionTreeClassifier
from sklearn import tree
import matplotlib as plt
import matplotlib.pyplot as pltpyplot
from sklearn.metrics import confusion_matrix

feature_set = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']
X = penguins[feature_set]
y = penguins.species
dtc_model = DecisionTreeClassifier(random_state = 1, max_depth = 1)

# Fit model

dtc_model.fit(X, y)

confusion_matrix(y, dtc_model.predict(X))
```

```{python, results = "hide"}
##
##
##
pltpyplot.figure()
tree.plot_tree(dtc_model, filled = True, feature_names = feature_set, class_names = list(set(list(penguins.species))))
pltpyplot.show()
```
:::

::: {style="margin-bottom:1500px;"}
:::

## Some alternatives

`R` benefits greatly from contributions from the community and there are mamy ways of performing the task albeit with improvements over the standard solution, often with a slightly more considerations for the user experience. `treeheatr` is a good example of this. It improves on the tree diagram and uses an additional heatmap for visualisation while keeping the API simple.

```{r, message = FALSE, fig.height = 5, fig.width = 10}
library(treeheatr)

heat_tree(sub_penguins, target_lab = 'species')
```

# Splitting data into train-test sets

While the previous code chunks use the entire data to fit a single tree model in each of the languages, this is obviously not the preferred practice for machine learning. 

We will use `tidymodels` for `R` from this point forward. 

::: {.left}
## `R`

```{r}
library(tidymodels)
penguins = penguins %>% dplyr::mutate(species = as.factor(species)) 
splitting = rsample::initial_split(data = penguins, prop = 0.75)

dtc_train_model = decision_tree() %>% 
  set_engine("rpart") %>% 
  set_mode("classification") %>% 
  fit(species ~ ., data = training(splitting))

dtc_predictions_tbl = bind_cols(
  pred_class = dtc_train_model %>% 
    predict(new_data = testing(splitting), type = "class"),
  pred_prob = dtc_train_model %>% 
    predict(new_data = testing(splitting), type = "prob"))
```

```{r}
dtc_predictions_tbl2 = bind_cols(testing(splitting), dtc_predictions_tbl)

cm = conf_mat(data = dtc_predictions_tbl2, truth = "species", estimate = ".pred_class")

cm
summary(cm)
```

:::

::: {.right}
## `Python`

```{python}
from sklearn.model_selection import train_test_split

train_X, test_X, train_y, test_y = train_test_split(X, y, random_state = 0, train_size = 0.75)

dtc_train_model = DecisionTreeClassifier(random_state = 1, max_depth = 2)
dtc_train_model = dtc_train_model.fit(train_X, train_y)
dtc_predictions = dtc_train_model.predict(test_X)
```

```{python}
from sklearn.metrics import classification_report

cr = classification_report(
y_true = test_y, 
y_pred = dtc_predictions)

print(cr)
```
:::

# ROC curve

::: {.left}
## `R`

```{r}
roc_curve(dtc_predictions_tbl2, truth = "species", estimate = ".pred_Adelie") %>% 
  ggplot(aes(x = 1 - specificity, y = sensitivity)) +
  geom_path() +
  geom_abline() +
  theme_bw()
```

:::

::: {.right}
## `Python`

```{python}
from sklearn.metrics import roc_curve
y_pred_prob = dtc_train_model.predict_proba(test_X)[:,1]
fpr, tpr, thresholds = roc_curve(test_y, y_pred_prob, pos_label = "Chinstrap")

# Plot ROC curve
pltpyplot.close()
pltpyplot.plot([0, 1], [0, 1], 'k--')
pltpyplot.plot(fpr, tpr)
pltpyplot.xlabel('False Positive Rate')
pltpyplot.ylabel('True Positive Rate')
pltpyplot.title('ROC Curve')
pltpyplot.show()
```
:::

# k-fold cross-validation

## Python

::: {.right}
```{python}
from sklearn.model_selection import RepeatedKFold
from sklearn.model_selection import cross_val_score
from sklearn.metrics import f1_score, make_scorer
import numpy as np

cv = RepeatedKFold(n_splits = 5, n_repeats = 20, random_state = 1)
dtc_train_model = DecisionTreeClassifier(random_state = 1, max_depth = 2)
scorer = make_scorer(f1_score, pos_label = 'Adelie')

scores = cross_val_score(estimator = dtc_train_model, X = train_X, y = train_y, scoring = scorer, cv = cv) ## n_jobs = -1 can be used for parallelisation

print("F1 statistics, mean (sd): " + str(np.round(np.mean(scores), 4)) + "(" + str(np.round(np.std(scores), 4)) + ")")
```
:::

# Imputation

## Removing rows with missing values

::: {.left}
## `R`
```{r}
missing_penguins = readr::read_csv("data/penguins.csv")
feature_set = c('bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g')
X = missing_penguins[,c('species', feature_set)]
X_dropped = na.omit(X)
```

:::

::: {.right}
## `Python`

```{python}
missing_penguins = pd.read_csv("data/penguins.csv")
missing_penguins.isnull().any()
missing_penguins.isnull().sum()

feature_set = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']
X = missing_penguins[feature_set]

# rows_with_missing_values = [row for row in X.index if X.iloc[row,:].isnull().any()]

X_dropped = X.dropna(axis = "index")
```
:::


## Median imputation 

::: {.left}
### `R`
```{r}
library(imputeMissings)
imputed_X = impute(data = X, method = "median/mode")
```

:::

::: {.right}
### `Python`
```{python}
from sklearn.impute import SimpleImputer

median_imputer = SimpleImputer(strategy = "median")
imputed_X = pd.DataFrame(median_imputer.fit_transform(X),columns=feature_set)
imputed_X.isnull().any()
```
:::
